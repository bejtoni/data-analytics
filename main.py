from etl.create_star_schema_tables import create_all_star_schema_tables
from etl.initial_archive_loader import run_initial_archive_loads
from etl.load_data import create_tables_and_load_data
from etl.fetch_rates import fetch_and_insert_exchange_rates
from etl.archive_loader import run_all_archive_loads
from etl.etl_to_mssql import load_all_to_dwh
from etl.fact_loader import load_fact_order

if __name__ == "__main__":
    print("ğŸš€ ETL pipeline started")

    # 1ï¸âƒ£ CSV â†’ staging PostgreSQL
    # create_tables_and_load_data()

    # 2ï¸âƒ£ API â†’ staging.exchange_rates
    # fetch_and_insert_exchange_rates()

    # 3ï¸âƒ£ SAMO INITIAL LOAD
    # run_initial_archive_loads()

    # # 3ï¸âƒ£ SCD2 â†’ archive.*  INCREMNTAL
    # run_all_archive_loads()

    create_all_star_schema_tables()

    # 4ï¸âƒ£ cleaned.* â†’ MSSQL dim_* tabele
    load_all_to_dwh()

    # 5ï¸âƒ£ cleaned.* â†’ MSSQL fact_order
    load_fact_order()

    print("âœ… ETL pipeline completed successfully")
